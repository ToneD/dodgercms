/**
 * Authorization Library.
 *
 * This source code is licensed under the MIT-style license found in the
 * LICENSE file in the root directory of this source tree.
 *
 * Author: Chris Zieba (zieba.chris@gmail.com)
*/

var dodgercms = dodgercms || {};

dodgercms.auth = (function() {
  'use strict';

  /**
   * Get authentication crendentials for the buckets.
   *
   * @param {Boolean} allOrNothing Optional parameter to return null if any of the crendtials are null
   * @return {Object}
  */
  var getCredentials = function(allOrNothing) {
    var credentials = {
      dataBucket: localStorage.getItem('dodgercms-data-bucket'),
      assetsBucket: localStorage.getItem('dodgercms-assets-bucket'),
      siteBucket: localStorage.getItem('dodgercms-site-bucket'),
      accessKey: localStorage.getItem('dodgercms-access-key-id'),
      accessSecret: localStorage.getItem('dodgercms-secret-access-key')
    };

    // Exit if any credentials are missing
    if (allOrNothing) {
      for (var property in credentials) {
        if (credentials.hasOwnProperty(property)) {
          if (!credentials[property]) {
            return null;
          }
        }
      }
    }

    return credentials;
  };

  /**
   * Returns an endpoint for the application.
   *
   * @param {String} protocol Either http or https
   * @param {String} bucket The bucket being referenced
   * @param {String} location The data center the bucket resided in
   * @return {String}
  */
  var getEndpoint = function(protocol, bucket, location) {
    // Check for empty string because of bug in AWS SDK (https://github.com/aws/aws-sdk-js/issues/590)
    if (location === '') {
      location = 'us-east-1';
    } else if (location === 'EU') {
      location = 'eu-west-1';
    }

    var endpoint = protocol + bucket + '.s3-website-' + location + '.amazonaws.com/';

    return endpoint;
  };

  /**
   * Get an IAM policy for the federated user.
   *
   * @param {String} dataBucket The bucket for the markdown content
   * @param {String} assetsBucket The bucket for the uploads
   * @param {String} siteBucket The bucket for the front end website
   * @return {String}
  */
  var getPolicy = function(dataBucket, assetsBucket, siteBucket) {
    // This is the same policy as the user from where the token was generated
    var policy = '{' +
      '"Version": "2012-10-17",' +
      '"Statement": [' +
        '{' +
          '"Sid": "Stmt1427944232000",' +
          '"Effect": "Allow",' +
          '"Action": [' +
            '"s3:ListBucket",' +
            '"s3:GetObject",' +
            '"s3:DeleteObject",' +
            '"s3:PutObject",' +
            '"s3:GetBucketWebsite",' +
            '"s3:PutBucketWebsite",' +
            '"s3:DeleteBucketWebsite",' +
            '"s3:GetBucketLogging",' +
            '"s3:GetBucketVersioning",' +
            '"s3:GetBucketLocation"' +
          '],' +
          '"Resource": [' +
            '"arn:aws:s3:::' + dataBucket + '",' +
            '"arn:aws:s3:::' + dataBucket + '/*",' +
            '"arn:aws:s3:::' + assetsBucket + '",' +
            '"arn:aws:s3:::' + assetsBucket + '/*",' +
            '"arn:aws:s3:::' + siteBucket + '",' +
            '"arn:aws:s3:::' + siteBucket + '/*"' +
          ']' +
        '}' +
      ']' +
    '}';

    return policy;
  };

  /**
   * Handles the federated token creation and policy generation.
   *
   * @param {Object} params The bucket for the markdown content
   * @param {Boolean} callback
  */
  function login(params, callback) {
    // No params, just a callback
    if (arguments.length === 1) {
      // Swap the arguments
      callback = params;

      // Try and get the login info from local storage
      params = getCredentials(true);

      if (!params) {
        // The info was not present in storage, therefore the user needs to enter them again
        return callback('Could not login due to lack of user credentials.');
      }

      // Since they were already remembered
      params.remember = true;
    }

    // Make sure all fields are present
    var required = ['dataBucket', 'assetsBucket', 'siteBucket', 'accessKey', 'accessSecret'];
    for (var i=0; i < required.length; i+=1) {
      if (!params.hasOwnProperty(required[i]) && params[required[i]]) {
        // Pass the error message back
        return callback(required[i] + ' is a required field.');
      }
    }

    params.remember = params.hasOwnProperty('remember') ? Boolean(params.remember) : false;

    var sts = new AWS.STS({
      accessKeyId: params.accessKey,
      secretAccessKey: params.accessSecret,
      sslEnabled: true,
      apiVersion: '2011-06-15'
    });

    // This is the same policy as the IAM user from where the token was generated
    var policy = getPolicy(params.dataBucket, params.assetsBucket, params.siteBucket);

    var stsParams = {
      Name: 'dodgercms-buckets-policy',
      Policy: policy,
      // Duration of 36 hours
      DurationSeconds: 129600,
    };

    // Create the federated token for access to the buckets
    sts.getFederationToken(stsParams, function(err, data) {
      if (err) {
        return callback('Access Denied. Please make sure the acccess key and secret are correct and try again.');
      } else {
        var s3 = new AWS.S3({
          accessKeyId: data.Credentials.AccessKeyId,
          secretAccessKey: data.Credentials.SecretAccessKey,
          sessionToken: data.Credentials.SessionToken,
          sslEnabled: true
        });

        // Test the connection to each bucket
        async.each([params.dataBucket, params.assetsBucket], function(bucket, cb) {
          s3.headBucket({ Bucket: bucket }, function(err) {
            if (err) {
              cb('Access Denied. Please make sure the user attached to the access key has access to ' + bucket + '.');
            } else {
              cb();
            }
          });
        },
        // Handle any errors from the calls to the buckets
        function(err) {
          if (err) {
            return callback(err);
          } else {
            // Get the webiste information. This is needed so we can get the
            // domain and any redirect rules that we need.
            async.parallel([
              function(cb1) {
                s3.getBucketWebsite({ Bucket: params.siteBucket }, function(err, websiteData) {
                  if (err) {
                    cb1('Access Denied. Please make sure the user attached to the access key has access to ' + params.siteBucket + '.');
                  } else {
                    // Success
                    cb1(null, websiteData);
                  }
                });
              },
              function(cb1) {
                s3.getBucketLocation({ Bucket: params.siteBucket }, function(err, locationData) {
                  if (err) {
                    cb1('Access Denied. Please make sure the user attached to the access key has access to ' + params.siteBucket + '.');
                  } else {
                    // Success
                    cb1(null, locationData);
                  }
                });
              }
            ],
            function(err, results) {
              if (err) {
                callback(err);
              } else {
                //var website = results[0];
                var location = results[1];

                // This property will not exist if the bucket is "US Standard" (https://github.com/aws/aws-sdk-js/issues/590)
                var locationConstraint = (location.hasOwnProperty('LocationConstraint')) ? location.LocationConstraint : '';

                // The endpoint is needed for the templates
                var endpoint = getEndpoint('http://', params.siteBucket, locationConstraint);

                // Store the federated user and bucket in local session data
                sessionStorage.setItem('dodgercms-token-access-key-id', data.Credentials.AccessKeyId);
                sessionStorage.setItem('dodgercms-token-secret-access-key', data.Credentials.SecretAccessKey);
                sessionStorage.setItem('dodgercms-token-session-token', data.Credentials.SessionToken);

                // If the user selected "remember me" store their access key and secret in local storage
                if (params.remember) {
                  localStorage.setItem('dodgercms-access-key-id', params.accessKey);
                  localStorage.setItem('dodgercms-secret-access-key', params.accessSecret);
                }

                localStorage.setItem('dodgercms-data-bucket', params.dataBucket);
                localStorage.setItem('dodgercms-assets-bucket', params.assetsBucket);
                localStorage.setItem('dodgercms-site-bucket', params.siteBucket);
                localStorage.setItem('dodgercms-site-endpoint', endpoint);

                // All done
                callback(null, data);
              }
            });
          }
        });
      }
    });
  }

  /**
   * Removes the saved data from local storage.
  */
  function logout() {
    localStorage.removeItem('dodgercms-access-key-id');
    localStorage.removeItem('dodgercms-secret-access-key');
    localStorage.removeItem('dodgercms-data-bucket');
    localStorage.removeItem('dodgercms-assets-bucket');
    localStorage.removeItem('dodgercms-site-bucket');
    localStorage.removeItem('dodgercms-site-endpoint');

    redirect();
  }

  /**
   * Redirect the page.
  */
  function redirect(uri) {
    if (!uri) {
      // Use the login page as the default
      uri = location.protocol + '//' + location.host + '/login.html';
    }

    window.location.replace(uri);
  }

  return {
    login: login,
    logout: logout,
    redirect: redirect
  };
}());

/**
 * Library for working with a markdown entry.
 *
 * This source code is licensed under the MIT-style license found in the
 * LICENSE file in the root directory of this source tree.
 *
 * Author: Chris Zieba (zieba.chris@gmail.com)
*/

var dodgercms = dodgercms || {};

dodgercms.entry = (function() {
  'use strict';

  var DATA_KEY = '.dodgercms/data.json';

  /**
   * When an entry gets deleted.
   *
   * @param {String} key Access key
   * @param {String} dataBucket Bucket where the markdown files are
   * @param {String} siteBucket Bucket for the front end website
   * @param {Function} callback Callback function
  */
  function remove(key, dataBucket, siteBucket, callback) {
    dodgercms.s3.deleteObjects(key, dataBucket, function(err, data) {
      if (err) {
        callback(err);
      } else {
        dodgercms.s3.deleteObjects(key, siteBucket, function(err, data) {
          if (err) {
            callback(err);
          } else {
            callback(null, data);
          }
        });
      }
    });
  }

  /**
   * When an entry gets renamed.
   *
   * @param {String} source The original location of the key
   * @param {String} target The new location of the key
   * @param {String} dataBucket Bucket where the markdown files are
   * @param {String} siteBucket Bucket for the front end website
   * @param {Function} callback Callback function
  */
  function rename(source, target, dataBucket, siteBucket, callback) {
    dodgercms.s3.renameObjects(source, target, dataBucket, function(err, data) {
      if (err) {
        callback(err);
      } else {
        dodgercms.s3.renameObjects(source, target, siteBucket, function(err, data) {
          if (err) {
            callback(err);
          } else {
            // Removes from both buckets
            remove(source, dataBucket, siteBucket, callback);
          }
        });
      }
    });
  }

  /**
   * Creates a new entry if it does not exist, or updates an existing entry.
   *
   * @param {String} key The key name
   * @param {String} title The title of the entry
   * @param {String} content The markdown content
   * @param {String} bucket The front end bucket
   * @param {String} endpoint The endpoint for the bucket
   * @param {Function} callback Callback function
  */
  function upsert(key, title, content, bucket, endpoint, callback) {
    async.waterfall([
      function(waterfallCb) {
        var options = {
          renderer: new marked.Renderer(),
          gfm: true,
          tables: true,
          breaks: false,
          pedantic: false,
          sanitize: true,
          smartLists: true,
          smartypants: false,
          highlight: function(code) {
            return hljs.highlightAuto(code).value;
          }
        };

        // Convert the content to HTML
        marked(content, options, function(err, data) {
          if (err) {
            waterfallCb(err);
          } else {
            waterfallCb(null, data);
          }
        });
      },
      // Process the templates
      function(body, waterfallCb) {
        var modified = new Date();

        var context = {
          key: key,
          title: title,
          modified: modified.toLocaleString(),
          body: body,
          bucket: bucket,
          endpoint: endpoint,
          dataKey: DATA_KEY
        };

        var entry = dodgercms.templates['entry.html'];
        var html = entry(context);

        waterfallCb(null, html);
      },
      // Upload the key to S3
      function(html, waterfallCb) {
        var params = {
          Bucket: bucket,
          Key: key,
          Body: html,
          ContentType: 'text/html; charset=UTF-8',
          Expires: 0,
          CacheControl: 'public, max-age=0, no-cache',
          Metadata: {
            'title': title
          }
        };

        dodgercms.s3.upload(params, function(err, data) {
          if (err) {
            waterfallCb(err);
          } else {
            waterfallCb(null);
          }
        });
      }
    ],
    // Callback
    function(err, result) {
      if (err) {
        callback(err);
      } else {
        callback(null, result);
      }
    });
  }

  /**
   * Generates the menu data.
   *
   * @param {String} bucket The front end bucket
   * @param {String} endpoint The endpoint for the bucket
   * @param {Function} callback Callback function
  */
  function menu(bucket, endpoint, callback) {
    async.waterfall([
      // The navigation needs to be updated
      function(waterfallCb) {
        dodgercms.s3.listObjects(null, bucket, function(err, data) {
          if (err) {
            waterfallCb(err);
          } else {
            waterfallCb(null, data);
          }
        });
      },
      // Filter unwanted files
      function(data, waterfallCb) {
        var contents = data.Contents;
        for (var i = contents.length -1; i >= 0 ; i-=1) {
          // Keys beginning with a period are treated as hidden or system files
          if (contents[i].Key.substr(0, 1) === '.') {
            contents.splice(i, 1);
          }
        }

        waterfallCb(null, contents);
      },
      // Takes the files from the s3 bucket
      function(data, waterfallCb) {
        var keys = [];

        // Get each object in parallel
        async.each(data, function(object, cb) {
          dodgercms.s3.headObject(object.Key, bucket, function(err, objectData) {
            if (err) {
              cb(err);
            } else {
              // Add the Key attribute
              objectData.Key = object.Key;
              keys.push(objectData);
              cb(null);
            }
          });

        },
        function(err) {
          if (err) {
            waterfallCb(err);
          } else {
            waterfallCb(null, keys);
          }
        });
      },
      // Takes an array of keys and builds a tree
      function(keys, waterfallCb) {
        var tree = [];

        // A reference to the parentScope is needed so we can add the index if needed
        function buildFromSegments(scope, parentScope, keyParts, pathSegments, isFolder, keyLabel) {
          // Remove the first segment from the path
          var current = pathSegments.shift();

          // Keep track of the key, which is the link to the entry
          keyParts.push(current);

          // The label defaults to the current part if no other title or folder label is added
          var label = current;

          // See if that segment already exists in the current scope
          var found = findInScope(scope, current);

          // If we did not find a match, create the new object for this path segment
          if (!found) {
            var key = keyParts.join('/');

            // Check if the last part in the path segment
            if (!pathSegments.length) {
              // If the key is a folder we need to add a trailing slash
              if (isFolder) {
                key += '/';
              }

              if (keyLabel) {
                label = keyLabel;
              }
            } else {
              // If there are more parts then the key must be a folder
              key += '/';
            }

            found = {
              key: key,
              part: current,
              index: (!pathSegments.length && current === 'index') ? true : false,
              // The link is filled in later if the folder contains an index
              link: (isFolder) ? null : key,
              label: label,
              children: false
            };

            // Add the link in for folders which have an index file
            if (parentScope && current === 'index') {
              parentScope.link = parentScope.key;
            }

            scope.push(found);
          } else {
            // The label needs to be applied if not already
            if (!pathSegments.length && isFolder && keyLabel) {
              found.label = keyLabel;
            }
          }

          // If there are still path segments left, we need to create
          // a children array (if we haven't already) and recurse further
          if (pathSegments.length) {
            found.children = found.children || [];
            buildFromSegments(found.children, found, keyParts, pathSegments, isFolder, keyLabel);
          }
        }

        // Attempts to find a path segment in the current scope
        function findInScope(scope, find) {
          for (var i = 0; i < scope.length; i++) {
            if (scope[i].part === find) {
              return scope[i];
            }
          }
        }

        keys.forEach(function(object) {
          var key = object.Key;

          // If it ends with a slash it's a directory
          var isFolder = (key.substr(-1) === '/') ? true : false;
          var label = (isFolder) ? object.Metadata.label : object.Metadata.title;

          // Remove the last slash if is exists so there is no empty string in the split array
          var parts = object.Key.replace(/\/\s*$/, '').split('/');

          buildFromSegments(tree, null, [], parts, isFolder, label);
        });

        waterfallCb(null, tree);
      },
      // Upload the nav to the bucket
      function(data, waterfallCb) {
        var params = {
          Bucket: bucket,
          Key: DATA_KEY,
          Body: JSON.stringify(data),
          ContentType: 'application/json; charset=UTF-8',
          Expires: 0,
          CacheControl: 'public, max-age=0, no-cache'
        };
        dodgercms.s3.upload(params, function(err, data) {
          if (err) {
            waterfallCb(err);
          } else {
            waterfallCb(null, data);
          }
        });
      }
    ],
    function(err, result) {
      if (err) {
        callback(err);
      } else {
        callback(null, result);
      }
    });
  }

  return {
    upsert: upsert,
    remove: remove,
    rename: rename,
    menu: menu
  };
}());

/**
 * Wrapper around the AWS SDK functions.
 *
 * This source code is licensed under the MIT-style license found in the
 * LICENSE file in the root directory of this source tree.
 *
 * Author: Chris Zieba (zieba.chris@gmail.com)
*/

var dodgercms = dodgercms || {};

dodgercms.s3 = (function() {
  'use strict';

  var ENCODING_TYPE = 'url';
  var API_VERSION = '2011-06-15';

  var s3 = null;

  /**
   * Initialize the connection object to S3.
   *
   * @param {String} accessKeyId Access key
   * @param {String} secretAccessKey Secret access key
   * @param {String} sessionToken The session token for the federated user
   * @param {Boolean} force Create a new S3 object if one exists already
   * @return {Object}
  */
  function init(accessKeyId, secretAccessKey, sessionToken, force) {

    if (!accessKeyId || !secretAccessKey || !sessionToken) {
      throw new Error('Missing arguments');
    }

    if (!s3 || force) {
      s3 = new AWS.S3({
        accessKeyId: accessKeyId,
        secretAccessKey: secretAccessKey,
        sessionToken: sessionToken,
        sslEnabled: true,
        // Duration of 36 hours
        DurationSeconds: 129600,
        apiVersion: API_VERSION,
        maxRetries: 1
      });
    }

    return s3;
  }

  /**
   * Returns the API version used by the AWS SDK.
   *
   * @return {String}
  */
  function getApiVersion() {
    return API_VERSION;
  }

  /**
   * Rename an object in S3.
   *
   * @param {String} source The current name of the key
   * @param {String} target The new name of the key
   * @param {String} bucket Where the key resides
   * @param {Function} callback Callback function
  */
  function renameObject(source, target, bucket, callback) {
    var params = {
      Bucket: bucket,
      MetadataDirective: 'COPY',
      // Copy Source must mention the source bucket and key: sourcebucket/sourcekey
      CopySource: bucket + '/' + source,
      Key: target
    };

    // Copy the key to a new location
    s3.copyObject(params, function(err, data) {
      if (err) {
        callback(err);
      } else {
        deleteObject(source, bucket, callback);
      }
    });
  }

  /**
   * Upload an object to S3.
   *
   * @param {Object} params Parameters
   * @param {Function} callback Callback function
  */
  function upload(params, callback) {
    s3.upload(params, function(err, data) {
      if (err) {
        callback(err);
      } else {
        callback(null, data);
      }
    });
  }

  /**
   * Upload an object to S3.
   *
   * @param {String} key The key name
   * @param {String} bucket The bucket where the key resides
   * @param {Function} callback Callback function
  */
  function getObject(key, bucket, callback) {
    var params = {
      Bucket: bucket,
      Key: key
    };

    s3.getObject(params, function(err, data) {
      if (err) {
        callback(err);
      } else {
        callback(null, data);
      }
    });
  }

  /**
   * Get meta information for a key in S3.
   *
   * @param {String} key The key name
   * @param {String} bucket The bucket where the key resides
   * @param {Function} callback Callback function
  */
  function headObject(key, bucket, callback) {
    var params = {
      Bucket: bucket,
      Key: key
    };

    s3.headObject(params, function(err, data) {
      if (err) {
        callback(err);
      } else {
        callback(null, data);
      }
    });
  }

  /**
   * Upload a key to an S3 bucket.
   *
   * @param {String} key The key name
   * @param {String} bucket The bucket where the key resides
   * @param {Function} callback Callback function
  */
  function putObject(key, bucket, callback) {
    var params;

    // If there are two arguments and the first is an object we we given the params directly
    if (arguments.length === 2 && typeof key === 'object') {
      params = key;
      callback = bucket;
    } else {
      params = {
        Bucket: bucket,
        Key: key
      };
    }

    s3.putObject(params, function(err, data) {
      if (err) {
        callback(err);
      } else {
        callback(null, data);
      }
    });
  }

  /**
   * Delete a key in S3.
   *
   * @param {String} key The key name
   * @param {String} bucket The bucket where the key resides
   * @param {Function} callback Callback function
  */
  function deleteObject(key, bucket, callback) {
    var params = {
      Bucket: bucket,
      Key: key
    };

    s3.deleteObject(params, function(err, data) {
      // Do not throw an error if the key does not exist
      if (err && err.code !== 'NoSuckKey') {
        callback(err);
      } else {
        callback(null, data);

      }
    });
  }

  /**
   * Copy a key from one location to another.
   *
   * @param {String} source The original location of the key
   * @param {String} target Where to move the key to
   * @param {String} bucket The bucket where the key resides
   * @param {Function} callback Callback function
  */
  function copyObject(source, target, bucket, callback) {
    var params = {
      Bucket: bucket,
      MetadataDirective: 'COPY',
      // Copy Source must mention the source bucket and key: sourcebucket/sourcekey
      CopySource: bucket + '/' + source,
      Key: target
    };

    s3.copyObject(params, function(err, data) {
      if (err) {
        callback(err);
      } else {
        callback(null, data);

      }
    });
  }

  /**
   * Rename multiple objects from one location to another.
   *
   * @param {String} source The original location of the key
   * @param {String} target Where to move the key to
   * @param {String} bucket The bucket where the key resides
   * @param {Function} callback Callback function
  */
  function renameObjects(source, target, bucket, callback) {
    // If the key is a folder we want to copy each child
    if (source.substr(-1) === '/') {
      // Split the file path into an array of parts
      var parts = source.replace(/\/\s*$/, '').split('/');

      // Remove the last part off the file path
      parts.splice(-1, 1, target);

      // The key to replace the old directory
      var targetPrefix = parts.join('/') + '/';

      listObjects(source, bucket, function(err, data) {
        if (err) {
          callback(err);
        } else {
          var contents = data.Contents;

          // Copy each object in parallel
          async.each(contents, function(object, cb) {
            // Replace the source with the target
            var key = targetPrefix + object.Key.substr(source.length);

            dodgercms.s3.copyObject(object.Key, key, bucket, cb);
          }, function(err) {
            if (err) {
              callback(err);
            } else {
              // Remove all the files from the site bucket
              callback(null);
            }
          });
        }
      });
    } else {
      dodgercms.s3.copyObject(source, target, bucket, callback);
    }
  }

  /**
   * Delete multiple keys in S3.
   *
   * @param {String} key The key name
   * @param {String} bucket The bucket where the key resides
   * @param {Function} callback Callback function
  */
  function deleteObjects(key, bucket, callback) {
    // If the key is a folder we want to delete all keys inside the folder, as well so we
    // use the key name as a prefix but if its a file, no prefix will delete only the one item
    if (key.substr(-1) === '/') {
      listObjects(key, bucket, function(err, data) {
        if (err) {
          callback(err);
        } else {
          var contents = data.Contents;
          // Delete each object in parallel
          async.each(contents, function(object, cb) {
            dodgercms.s3.deleteObject(object.Key, bucket, cb);
          }, function(err) {
            if (err) {
              callback(err);
            } else {
              // Remove all the files from the site bucket
              callback(null);
            }
          });
        }
      });
    } else {
      // Just delete the one key
      dodgercms.s3.deleteObject(key, bucket, callback);
    }
  }

  /**
   * Get a list of all objects in an S3 bucket.
   *
   * @param {String} prefix Optional prefix used when searching for keys
   * @param {String} bucket The bucket to query objects from
   * @param {Function} callback Callback function
  */
  function listObjects(prefix, bucket, callback) {
    // The prefix is an optional argument
    if (arguments.length === 2) {
      callback = bucket;
      bucket = prefix;
      prefix = '';
    }

    var params = {
      Bucket: bucket,
      EncodingType: ENCODING_TYPE,
      MaxKeys: 1000,
      Prefix: prefix
    };

    s3.listObjects(params, function(err, data) {
      if (err) {
        callback(err);
      } else {
        callback(null, data);
      }
    });
  }

  /**
   * Gets meta data for multiple objects. Need to make a head
   * request for each key. Useful after getting a list of objects.
   *
   * @param {Array} contents A list of keys to query
   * @param {String} bucket The bucket where the keys reside
   * @param {Function} callback Callback function
  */
  function headObjects(contents, bucket, callback) {
    var keys = [];

    // Get each object in parallel
    async.each(contents, function(object, cb) {
      s3.headObject({
        Bucket: bucket,
        Key: object.Key
      }, function(err, data) {
        if (err) {
          cb(err);
        } else {
          // Add the key attribute
          data.Key = object.Key;
          keys.push(data);
          cb(null);
        }
      });
    },
    function(err) {
      if (err) {
        callback(err);
      } else {
        callback(null, keys);
      }
    });
  }

  return {
    init: init,
    getApiVersion: getApiVersion,
    getObject: getObject,
    upload: upload,
    headObject: headObject,
    putObject: putObject,
    copyObject: copyObject,
    deleteObject: deleteObject,
    deleteObjects: deleteObjects,
    renameObject: renameObject,
    renameObjects: renameObjects,
    listObjects: listObjects,
    headObjects: headObjects
  };
}());

/**
 * Collection of utility functions used in application.
 *
 * This source code is licensed under the MIT-style license found in the
 * LICENSE file in the root directory of this source tree.
 *
 * Author: Chris Zieba (zieba.chris@gmail.com)
*/

var dodgercms = dodgercms || {};

dodgercms.utils = (function() {
  'use strict';

  /**
   * Returns the possible folders based on the list of S3 keys.
   *
   * @param {Array} Keys from S3
   * @return {Array}
  */
  function getFolders(objects) {
    // Default to the root folder
    var folders = ['/'];

    // Loop through each object in the list
    for (var i = 0; i < objects.length; i+=1) {
      var key = objects[i].Key;

      // Split and remove last slash for directory
      var parts = key.replace(/\/\s*$/, '').split('/');

      for (var j = 0; j < parts.length; j+=1) {
        var isFolder = false;

        // If the last part in the key has a trailing slash or if the part
        // is in not the last elemenet it is a path, it is a folder
        if ((j === parts.length-1 && key.substr(-1) === '/') || j !== parts.length-1) {
          isFolder = true;
        }

        if (isFolder) {
          var folder = parts.slice(0, j+1).join('/') + '/';
          // Push only if unique
          if ($.inArray(folder, folders) < 0) {
            folders.push(folder);
          }
        }
      }
    }

    return folders;
  }

  /**
   * Creates a new folder in S3.
   *
   * @param {String} key The new key to place in S3
   * @param {String} dataBucket The bucket where the markdown resides
   * @param {String} siteBucket The front end website bucket
   * @param {Function} callback
  */
  function newFolder(key, dataBucket, siteBucket, callback) {
    dodgercms.s3.putObject(key, dataBucket, function(err, data) {
      if (err) {
        callback(err);
      } else {
        dodgercms.s3.putObject(key, siteBucket, function(err, data) {
          if (err) {
            callback(err);
          } else {
            // Check if a callback was supplied
            if (typeof callback !== 'undefined') {
              callback(null, key);
            }
          }
        });
      }
    });
  }

  /**
   * Checks if a given key is a folder.
   *
   * @param {String} key The key name
   * @return {Boolean}
  */
  function isFolder(key) {
    return (key.substr(-1) === '/') ? true : false;
  }

  /**
   * Returns the last part (file name) in the file path.
   *
   * @param {String} key The key name
   * @return {String} A new jsTree node
  */
  function getSlug(key) {
    var parts = key.split('/');
    return parts.pop();
  }

  return {
    newFolder: newFolder,
    isFolder: isFolder,
    getSlug: getSlug,
    getFolders: getFolders
  };
}());